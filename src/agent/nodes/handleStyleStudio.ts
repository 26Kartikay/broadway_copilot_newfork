import { z } from 'zod';
import { getTextLLM } from '../../lib/ai';
import { SystemMessage, BaseMessage } from '../../lib/ai/core/messages';
import { logger } from '../../utils/logger';
import { loadPrompt } from '../../utils/prompts';
import { InternalServerError } from '../../utils/errors';
import { GraphState, Replies } from '../state';
import { PendingType } from '@prisma/client';

const StyleStudioOutputSchema = z.object({
Â  reply_text: z.string(),
});

const styleStudioMenuButtons = [
Â  { text: 'Style for any occasion', id: 'style_studio_occasion' },
Â  { text: 'Vacation looks', id: 'style_studio_vacation' },
Â  { text: 'General styling', id: 'style_studio_general' },
];

export async function handleStyleStudio(state: GraphState): Promise<GraphState> {
Â  const { subIntent, conversationHistoryTextOnly, user, pending } = state;
Â  const userId = user.id;

Â  // --- START OF CONTEXT CHECK AND TRUNCATION (FIXED) ---
Â  let historyForLLM: BaseMessage[] = conversationHistoryTextOnly;
Â  
Â  if (subIntent && historyForLLM.length > 0) {
Â  Â  // Get the last message.
Â  Â  const latestUserMessage = historyForLLM.at(-1); 
Â  Â  
Â  Â  // Check 1 & 2: Ensure the message object exists AND its content is definitely a string
Â  Â  if (latestUserMessage && typeof latestUserMessage.content === 'string') {
Â  Â  Â  Â  
Â  Â  Â  Â  // FIX: Use 'as unknown as string' to correctly handle the complex MessageContent type
Â  Â  Â  Â  const isServiceSwitch = styleStudioMenuButtons.some(
Â  Â  Â  Â  Â  button => (latestUserMessage.content as unknown as string).trim() === button.id
Â  Â  Â  Â  );

Â  Â  Â  Â  if (isServiceSwitch) {
Â  Â  Â  Â  Â  // If a switch was detected, truncate the history to ONLY include the latest message.
Â  Â  Â  Â  Â  logger.debug({ userId, subIntent }, 'Sub-service switch detected via button payload. Truncating LLM history.');
Â  Â  Â  Â  Â  
Â  Â  Â  Â  Â  // We assert that latestUserMessage is a BaseMessage before array assignment
Â  Â  Â  Â  Â  historyForLLM = [latestUserMessage as BaseMessage]; 
Â  Â  Â  Â  }
Â  Â  }
Â  }
Â  // --- END OF CONTEXT CHECK AND TRUNCATION (FIXED) ---

Â  if (!subIntent) {
Â  Â  // Send menu if not already pending
Â  Â  if (pending !== PendingType.STYLE_STUDIO_MENU) {
Â  Â  Â  const replies: Replies = [
Â  Â  Â  Â  {
Â  Â  Â  Â  Â  reply_type: 'quick_reply',
Â  Â  Â  Â  Â  reply_text: 'Welcome to Style Studio! Choose a styling service:',
Â  Â  Â  Â  Â  buttons: styleStudioMenuButtons,
Â  Â  Â  Â  },
Â  Â  Â  ];
Â  Â  Â  return {
Â  Â  Â  Â  ...state,
Â  Â  Â  Â  assistantReply: replies,
Â  Â  Â  Â  pending: PendingType.STYLE_STUDIO_MENU,
Â  Â  Â  Â  lastHandledPayload: null,
Â  Â  Â  };
Â  Â  } else {
Â  Â  Â  // Possibly user repeated same menu state; do nothing
Â  Â  Â  return { ...state, assistantReply: [] };
Â  Â  }
Â  }

Â  try {
Â  Â  const intentKey = subIntent.replace('style_studio_', ''); // e.g. 'occasion', 'vacation', 'general'
Â  Â  const systemPromptText = await loadPrompt(`handlers/style_studio/${intentKey}.txt`);
Â  Â  const systemPrompt = new SystemMessage(systemPromptText);

Â  Â  const result = await getTextLLM()
Â  Â  Â  .withStructuredOutput(StyleStudioOutputSchema)
Â  Â  Â  .run(systemPrompt, historyForLLM, state.traceBuffer, 'handleStyleStudio'); // ðŸ‘ˆ USING THE FILTERED HISTORY

Â  Â  const replies: Replies = [
Â  Â  Â  { reply_type: 'text', reply_text: result.reply_text },
Â  Â  ];

Â  Â  logger.debug({ userId, subIntent, replies }, 'Generated Style Studio reply');
Â  Â  return { ...state, assistantReply: replies, pending: PendingType.NONE };
Â  } catch (err) {
Â  Â  logger.error({ userId, err }, 'Error in handleStyleStudio');
Â  Â  throw new InternalServerError('Failed to handle Style Studio request', { cause: err });
Â  }
}